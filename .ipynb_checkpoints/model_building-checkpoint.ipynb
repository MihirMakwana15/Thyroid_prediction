{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7a4123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pickle\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0f27eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"Model_creation.log\", level=logging.INFO, format='%(asctime)s %(message)s',\n",
    "\t\t\t\t\tdatefmt=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613a44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Reading training dataset........\")\n",
    "x_train=pd.read_csv(\"x_train.csv\")\n",
    "y_train=pd.read_csv(\"y_train.csv\")\n",
    "logging.info(\"Read the training data successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c91ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Reading testing dataset........\")\n",
    "x_test =  pd.read_csv(\"x_test.csv\")\n",
    "y_test =  pd.read_csv(\"y_test.csv\")\n",
    "logging.info(\"Read the testing data successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1dfc21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Reading validation dataset........\")\n",
    "x_valid =  pd.read_csv(\"x_valid.csv\")\n",
    "y_valid =  pd.read_csv(\"y_valid.csv\")\n",
    "logging.info(\"Read the validation data successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1b6d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creatinf pipelines\n",
    "pipe4=Pipeline([(\"minmax_scalar\",MinMaxScaler()),(\"XGboost\",XGBClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f3aadb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe6 = Pipeline([(\"minmax_scalar\", MinMaxScaler()), (\"random_forest\", RandomForestClassifier())])\n",
    "logging.info(\"Created pipelines for our models.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e015ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=[\"FTI\",\"TSH\",\"TT4\",\"T4U\"] #Permutation method of feature selection was used\n",
    "logging.info(\"Selected top 4 important features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c96f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using randomized search cv to get the best parameter values\n",
    "logging.info(\"Hyperparameter tuning intiated in Random Forest.......\")\n",
    "def hyparameter_tuning_rf(model, x, y, final_features):\n",
    "    params = { \n",
    "        'random_forest__max_depth': [15, 25, 30, 35, 45, 50],\n",
    "        'random_forest__n_estimators': [50, 70, 100, 200, 300, 400]\n",
    "             }\n",
    "    tuned_model = RandomizedSearchCV(model, param_distributions=params, n_iter=3, cv=3)\n",
    "    tuned_model.fit(x[final_features], y)\n",
    "    logging.info(tuned_model.best_params_)\n",
    "    return tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01066162",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "C:\\Users\\Mihir15\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Random forest training started......\")\n",
    "model_rf = hyparameter_tuning_rf(pipe6, x_train, y_train, features)\n",
    "features = [\"FTI\", \"TSH\", \"TT4\", \"T4U\"] # Permutation method of feature selection was used.\n",
    "logging.info(\"Random forest trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ea4dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using randomized search cv to get the best parameter values\n",
    "logging.info(\"Hyperparameter tuning intiated in XGBoost.......\")\n",
    "def hyparameter_tuning_xgb(model, x, y, final_features):\n",
    "    params = { \n",
    "       'XGboost__max_depth': [3,4,5,7,10,15,],\n",
    "       'XGboost__learning_rate': [0.001, 0.0003, 0.005],\n",
    "       'XGboost__n_estimators': [1000, 1500, 8000, 10000],\n",
    "       'XGboost__colsample_bytree': [0.3, 0.5, 0.7, 0.9]\n",
    "             }\n",
    "    tuned_model = RandomizedSearchCV(model, param_distributions=params, n_iter=3, cv=3)\n",
    "    tuned_model.fit(x[final_features], y)\n",
    "    logging.info(tuned_model.best_params_)\n",
    "    return tuned_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b14bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"XGBoost training started.\")\n",
    "model_xgb = hyparameter_tuning_xgb(pipe4, x_train, y_train, features)\n",
    "logging.info(\"XGBoost trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2daae1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally saving our model as a pickel file. (For deployment)\n",
    "pickle.dump(model_rf, open('Random_forest_model.pkl','wb'))\n",
    "logging.info(\"Successfully saved Random forest as pickle file.\")\n",
    "pickle.dump(model_rf, open('XGBoost_model.pkl','wb'))\n",
    "logging.info(\"Successfully saved XGBoost as pickle file.\")\n",
    "logging.info(\"Sucessfully executed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
