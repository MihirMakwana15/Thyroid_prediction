{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a39db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4192fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=\"Data_proprocessing _part_2.log\", level=logging.INFO, format='%(asctime)s %(message)s',\n",
    "\t\t\t\t\tdatefmt=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b949b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Reading the dataset.........\")\n",
    "df=pd.read_csv(\"data_processed_1.csv\")\n",
    "logging.info(\"Read the dataset successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7589c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We saw that the null values were imputed by a \"?\" to keep things simpple i convert the \"?\" into numpy null value\n",
    "df.replace({\"?\":np.nan},inplace=True)\n",
    "logging.info(\"Replaced all ? into Null values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef91fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns \"TBG\" and \"T3\" has a lot of null values. Imputing these null values might reduce variance and might tease \n",
    "# the model into giving more importance to a particular case.\n",
    "df.drop(columns=[\"TBG\",\"T3\"],inplace=True)\n",
    "logging.info(\"Droped column TBG and T3 for high missing values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd45789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column \"sex\" has a few null values and I thought imputing them with \"unknown\" makes more sense \n",
    "# than male \"M\" or \"female\" \"F\".\n",
    "df.Sex.fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53e016a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the datatypes of continous features into numeric type.\n",
    "df.TSH=pd.to_numeric(df.TSH)\n",
    "df.TT4=pd.to_numeric(df.TT4)\n",
    "df.T4U=pd.to_numeric(df.T4U)\n",
    "df.FTI=pd.to_numeric(df.FTI)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7b311f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers\n",
    "index_age=df[df[\"Age\"]>100].index\n",
    "df.drop(index_age,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a580afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing TSH vallule higher than 15.that's quiet rare.\n",
    "index_tsh=df[df[\"TSH\"]>15].index\n",
    "df.drop(index_tsh,inplace=True)\n",
    "logging.info(\"Dropped outliers from TSH features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "474c76fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the catgorical Features.\n",
    "df_dummy=pd.get_dummies(df)\n",
    "logging.info(\"Encoded the categorical features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b98c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputting null values using KNNImputer.\n",
    "logging.info(\"Imputation of trainind and testing missing values with KNNImputer initiated.....\")\n",
    "def Imputation(df):\n",
    "    imputer=KNNImputer(n_neighbors=3)\n",
    "    df_1=imputer.fit_transform(df)\n",
    "    df_2=pd.DataFrame(df_1,columns=df.columns)\n",
    "    return df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c24501f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final=Imputation(df_dummy[:7000])\n",
    "logging.info(\"Successfully imputed the nissung values in train and test.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3be45f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into train ,test and validation to prevent data leakage.\n",
    "validation_data=df_dummy[7000:]\n",
    "x_train,x_test,y_train,y_test=train_test_split(df_final.drop(columns=\"outcome\"),df_final[\"outcome\"],test_size=0.2)\n",
    "logging.info(\"Created training ,testing and validation dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88bd5a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"Initiated imputation in vallidation dataset.\")\n",
    "valid_final=Imputation(validation_data)\n",
    "logging.info(\"Successfully imputed in validation dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88ce0e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixing the imbalanced data by creating duplicate records.\n",
    "logging.info(\"Fixing imbalanced data initiated.....\")\n",
    "def balance_data(x,y):\n",
    "    ros=RandomOverSampler(random_state=42)\n",
    "    x_sample,y_sample=ros.fit_resample(x,y)\n",
    "    return x_sample,y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7834dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train=balance_data(x_train,y_train)\n",
    "logging.info(\"fixed imbalanced data in train dataset.\")\n",
    "x_test,y_test=balance_data(x_test,y_test)\n",
    "logging.info(\"fixed imbalanced data  in test dataset.\")\n",
    "x_valid,y_valid=balance_data(valid_final.drop(columns=\"outcome\"),valid_final[\"outcome\"])\n",
    "logging.info(\"fixed imbalanced data in validation dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fcedf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"saving training data......\")\n",
    "x_train.to_csv(\"x_train.csv\",index=False)\n",
    "y_train.to_csv(\"y_train.csv\",index=False)\n",
    "logging.info(\"Successfully saved the testing data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b90eecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"saving the testing data.....\")\n",
    "x_test.to_csv(\"x_test.csv\", index=False)\n",
    "y_test.to_csv(\"y_test.csv\", index=False)\n",
    "logging.info(\"Successfully saved the testing data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d1684dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"saving the validation data......\")\n",
    "x_valid.to_csv(\"x_valid.csv\", index=False)\n",
    "y_valid.to_csv(\"y_valid.csv\", index=False)\n",
    "logging.info(\"Successfully saved the validation data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
